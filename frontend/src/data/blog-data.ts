// Auto-generated blog data
// This file is generated by scripts/process-content.js

export interface Article {
  slug: string;
  frontmatter: {
    title: string;
    description: string;
    date: string;
    category: string;
    tags: string[];
    author: string;
    readTime: string;
    coverImage?: string;
    published?: boolean;
    draft?: boolean;
  };
  content: string;
  excerpt: string;
  headings: {
    id: string;
    text: string;
    level: number;
  }[];
}

export interface Category {
  name: string;
  slug: string;
  description: string;
  count: number;
}

export const blogData = {
  articles: [
  {
    "slug": "kubernetes-horizontal-scaling",
    "frontmatter": {
      "title": "Ship to Scale: The Journey from Containers to Kubernetes Horizontal Scaling",
      "description": "A comprehensive, production-grade guide to modern orchestration: From simple Docker containers to fully automated, self-healing Kubernetes clusters with Horizontal Pod Autoscaling (HPA).",
      "date": "2024-01-10",
      "category": "Cloud Native",
      "tags": [
        "Kubernetes",
        "K8s",
        "HPA",
        "DevOps",
        "Scaling",
        "Cloud Native"
      ],
      "author": "Khairil Rahman",
      "readTime": "26 min read",
      "published": true
    },
    "content": "\r\nYou've built your microservices, integrated Redis for caching, and RabbitMQ for event-driven magic. Everything works perfectly on your machine with `docker-compose`. But then comes the real world. Your user base doubles overnight. A marketing campaign brings 10x more traffic. Suddenly, your single VPS is gasping for air.\r\n\r\nManually running `docker-compose up --scale` on a SSH terminal at 3 AM is not a strategy—it's a nightmare. This is where **Kubernetes (K8s)** transforms you from a \"Developer\" into a \"Cloud Native Engineer.\"\r\n\r\n## 1. The Scaling Problem: Why Containers Aren't Enough\r\n\r\nContainers (Docker) solved the \"it works on my machine\" problem. But they don't solve the \"it works at scale\" problem. \r\n\r\n**Without Orchestration, you have to manually handle:**\r\n- **Placement:** Which server has enough RAM for this container?\r\n- **Restarts:** What happens if the container crashes?\r\n- **Routing:** How do you update the load balancer every time a container's IP changes?\r\n- **Scaling:** How do you add replicas in response to real-time CPU spikes?\r\n\r\nKubernetes is the \"Operating System for the Cloud\" that automates all of this.\r\n\r\n## 2. Kubernetes Architecture: The Brain and the Muscle\r\n\r\nKubernetes follows a **Master-Worker** architecture. Understanding this is key to understanding how your app stays alive.\r\n\r\n### The Control Plane (The Brain)\r\n- **API Server:** The front door. Every command goes through here.\r\n- **Etcd:** The source of truth. A distributed database storing the entire cluster state.\r\n- **Scheduler:** The \"Traffic Controller.\" It decides which node should run which Pod.\r\n- **Controller Manager:** The \"Watchdog.\" It ensures the current state matches the desired state.\r\n\r\n### The Worker Nodes (The Muscle)\r\n- **Kubelet:** The agent that talks to the Master and manages local containers.\r\n- **Kube-Proxy:** Manages the network rules (IP tables) for traffic routing.\r\n- **Container Runtime:** (Usually `containerd`) What actually runs the container.\r\n\r\n```mermaid\r\ngraph TB\r\n    subgraph Control_Plane\r\n        API[API Server]\r\n        ETCD[(etcd)]\r\n        SCH[Scheduler]\r\n        CM[Controller Manager]\r\n    end\r\n\r\n    subgraph Worker_Node_1\r\n        P1[Pod: User Service]\r\n        P2[Pod: Redis]\r\n        K1[Kubelet]\r\n    end\r\n\r\n    subgraph Worker_Node_2\r\n        P3[Pod: User Service - Replica]\r\n        P4[Pod: RabbitMQ]\r\n        K2[Kubelet]\r\n    end\r\n\r\n    API --- Nodes\r\n    Nodes --- K1\r\n    Nodes --- K2\r\n```\r\n\r\n## 3. The Front Door: Ingress and Traffic Management\r\n\r\nIn Kubernetes, you don't expose Pods directly. You use **Services** and **Ingress**.\r\n\r\n### A. The Service object\r\nA stable IP and DNS name that points to a group of Pods. It provides internal load balancing.\r\n\r\n### B. The Ingress Controller\r\nThe entry point from the internet. It handles:\r\n- **SSL Termination:** Your app doesn't need to worry about HTTPS certificates.\r\n- **Path-based Routing:** `/api/auth` goes to User Service, `/api/payments` goes to Payment Service.\r\n- **Rate Limiting:** At the edge, before it even hits your code.\r\n\r\n```mermaid\r\nflowchart LR\r\n    Internet((Internet)) --> Ing[Ingress: Traefik / Nginx]\r\n    Ing -->|/auth| SvcA[Service: User]\r\n    Ing -->|/pay| SvcB[Service: Payment]\r\n    \r\n    SvcA --> P1[Pod A1]\r\n    SvcA --> P2[Pod A2]\r\n    SvcB --> P3[Pod B1]\r\n```\r\n\r\n## 4. The \"Holy Grail\": Horizontal Pod Autoscaler (HPA)\r\n\r\nHPA is what separates the boys from the men in infrastructure design. It allows your app to scale **Dynamically** based on load.\r\n\r\n### The Feedback Loop:\r\n1.  **Metrics Server** collects resource data (CPU/RAM) from every pod every 15 seconds.\r\n2.  **HPA Controller** compares the current usage to your target (e.g., 70% CPU).\r\n3.  **Calculation:** If usage > 70%, calculate how many more pods are needed.\r\n4.  **Action:** Update the Deployment's `replica` count.\r\n\r\n```mermaid\r\nsequenceDiagram\r\n    participant User as Traffic Surge\r\n    participant Met as Metrics Server\r\n    participant HPA as HPA Controller\r\n    participant Dep as Deployment\r\n    \r\n    User->>Dep: High Traffic\r\n    Note right of Dep: Pods hitting 90% CPU\r\n    loop Every 15s\r\n        HPA->>Met: Fetch CPU Metrics\r\n        Met-->>HPA: Current: 90%, Target: 70%\r\n    end\r\n    HPA->>Dep: Scale Up: Replicas 1 -> 4\r\n    Dep->>Dep: Start 3 new Pods\r\n    Note over Dep: Traffic balanced across 4 Pods\r\n```\r\n\r\n## 5. Deployment Strategies: Zero Downtime\r\n\r\nUpdating a monolith often involves service interruption. In K8s, we use:\r\n\r\n### Rolling Updates\r\nK8s stops the old pod only after the new pod has passed its **Readiness Probe**. This ensures your users never see a 404 or 502 error during a deployment.\r\n\r\n### Blue-Green Deployments\r\nRun the new version in a separate \"Green\" environment. Once tested, flip the Ingress routing to point to Green.\r\n\r\n## 6. Persistence: Databases on K8s\r\n\r\nContainers are meant to be \"Stateless.\" But your database needs to keep its data.\r\n- **PersistentVolume (PV):** A piece of storage (e.g., a disk on your VPS or a Cloud Disk).\r\n- **PersistentVolumeClaim (PVC):** A \"ticket\" a Pod uses to request storage.\r\n\r\n```yaml\r\n# Simplified PVC Example\r\napiVersion: v1\r\nkind: PersistentVolumeClaim\r\nmetadata:\r\n  name: postgres-pvc\r\nspec:\r\n  accessModes:\r\n    - ReadWriteOnce\r\n  resources:\r\n    requests:\r\n      storage: 10Gi\r\n```\r\n\r\n## 7. Security: Secrets and ConfigMaps\r\n\r\nNever store credentials in your Docker image!\r\n- **ConfigMap:** Public configuration (e.g., `PORT: 3000`).\r\n- **Secrets:** Base64 encoded sensitive data (`DB_PASSWORD`). These are mounted into the container as environment variables or files.\r\n\r\n## 8. CI/CD: The Automated Pipeline\r\n\r\nA modern engineer never runs `kubectl apply` manually for production.\r\n1. **GitHub Commit:** Push code to `main`.\r\n2. **GitHub Actions:** \r\n   - Run tests.\r\n   - Build Docker Image.\r\n   - Push to Docker Hub.\r\n   - SSH into K8s Cluster and run `kubectl set image`.\r\n3. **K8s:** Perception of new version and performance of a **Rolling Update**.\r\n\r\n## 9. Best Practices and Common Pitfalls\r\n\r\n> [!TIP]\r\n> Never set your HPA target to 100% CPU. By the time it hits 100%, the Pod might already be unresponsive, and scaling out will be too slow to save the system.\r\n\r\n- **Always set Resource Requests/Limits:** If you don't tell K8s how much RAM a pod needs, the Scheduler will fly blind, leading to \"Node Pressure\" and cluster crashes.\r\n- **Use Health Probes:** Without `livenessProbe` and `readinessProbe`, K8s doesn't know if your app is actually working or just sitting there in a zombie state.\r\n\r\n## 10. Conclusion: The Unicorn Engineer Path\r\n\r\nMastering Kubernetes, Ingress, and HPA is the final frontier for a backend developer. Companies in the **Unicorn** category (Grab, Sea, Traveloka) operate hundreds of microservices. They don't just need people who can write code; they need people who can design **Systems that Scale and Heal themselves.**\r\n\r\nBy building a cluster and implementing HPA, you prove that you have the foresight and the technical depth to build for millions of users.\r\n\r\n> \"Kubernetes is the ultimate tool for developers who want to manage their infrastructure like code.\"\r\n\r\n### FAQ\r\n\r\n<details>\r\n<summary>What is the difference between Docker and Kubernetes?</summary>\r\nDocker is about **Packaging** your app into a container. Kubernetes is about **Operating** thousands of those containers across multiple servers.\r\n</details>\r\n\r\n<details>\r\n<summary>Is K3s the same as K8s?</summary>\r\nYes! K3s is a lightweight, certified Kubernetes distribution perfect for edge computing and single-server VPS setups. It uses less RAM but has the full K8s API.\r\n</details>\r\n\r\n<details>\r\n<summary>Can I run K8s on a 1GB RAM VPS?</summary>\r\nTechnically possible with K3s, but not recommended. For a stable cluster with monitoring and several services, aim for at least 4GB of RAM.\r\n</details>\r\n\r\n_This concludes our \"Unicorn-Grade System Design\" series._\r\n\r\n_Check out my other articles on Microservices, Redis, and RabbitMQ._\r\n",
    "excerpt": "You've built your microservices, integrated Redis for caching, and RabbitMQ for event-driven magic. Everything works perfectly on your machine with docker-compo...",
    "headings": []
  },
  {
    "slug": "event-driven-rabbitmq",
    "frontmatter": {
      "title": "Orchestrating Systems: A Comprehensive Guide to Event-Driven Architecture with RabbitMQ",
      "description": "From tight coupling to decoupled excellence: A masterclass on building resilient, event-driven microservices using the AMQP standard and RabbitMQ orchestration.",
      "date": "2024-01-09",
      "category": "Infrastructure",
      "tags": [
        "RabbitMQ",
        "Message Broker",
        "System Design",
        "EDA",
        "Scalability"
      ],
      "author": "Khairil Rahman",
      "readTime": "24 min read",
      "published": true
    },
    "content": "\r\nIn a classic monolithic application, communication is simple: you call a function, it does some work, and returns a result. But in a **Microservices** world, services talk across a network. If Service A calls Service B and waits for a response (Synchronous), you create a brittle system where a failure in B cascades to A, potentially taking down your entire platform.\r\n\r\nThe solution to this \"cascading failure\" is **Event-Driven Architecture (EDA)**. And at the heart of many high-performance EDA implementations lies **RabbitMQ**.\r\n\r\n## 1. What is Event-Driven Architecture (EDA)?\r\n\r\nEDA is a software architecture pattern where the flow of the program is determined by **Events**—significant changes in state (e.g., `UserSignedUp`, `PaymentProcessed`, `CourseCompleted`).\r\n\r\n### The Three Pillars of EDA:\r\n1.  **Decoupling:** The \"Signup Service\" shouldn't know that an \"Email Service\" exists. It simply announces that a signup occurred.\r\n2.  **Scalability:** You can easily add more listeners (e.g., a \"Marketing Service\") without touching a single line of the Signup Service code.\r\n3.  **Resilience:** If the Email Service is down, the message stays safely in the queue. When the service recovers, it processes the pending work. The user never sees an error.\r\n\r\n## 2. RabbitMQ: The Postal Service for Data\r\n\r\nRabbitMQ is a message broker that implements the Advanced Message Queuing Protocol (AMQP). Think of it as a sophisticated postal service.\r\n\r\n### Core Anatomy:\r\n- **Producer:** The app sending the message (The sender).\r\n- **Exchange:** The mail room. It receives messages and decides where to route them.\r\n- **Queue:** The mailbox. Where messages wait to be picked up.\r\n- **Consumer:** The app processing the message (The recipient).\r\n- **Binding:** The rules connecting an Exchange to a Queue.\r\n\r\n```mermaid\r\ngraph LR\r\n    P[Producer] --> E{Exchange}\r\n    E -->|Binding / Routing Key| Q1[Queue A]\r\n    E -->|Binding / Routing Key| Q2[Queue B]\r\n    Q1 --> C1[Consumer 1]\r\n    Q2 --> C2[Consumer 2]\r\n```\r\n\r\n## 3. Mastering Exchange Types\r\n\r\nThe true power of RabbitMQ lies in its routing flexibility. Unlike simple \"Point-to-Point\" queues, RabbitMQ uses four types of Exchanges to handle different logic.\r\n\r\n### A. Direct Exchange\r\nRoutes messages to queues based on an **Exact Match** of the routing key.\r\n*   **Best for:** Unicasting. Sending an `error` log to an `error-processor` queue.\r\n\r\n### B. Fanout Exchange\r\nBroadcasts messages to **Every** queue bound to it. It ignores the routing key.\r\n*   **Best for:** Broad-scale updates. A news alert that every user should receive.\r\n\r\n### C. Topic Exchange\r\nThe most versatile. Routes based on wildcard patterns. \r\n- `*` matches exactly one word.\r\n- `#` matches zero or more words.\r\n*   **Best for:** Complex systems like an IoT platform routing data from `region.building.sensor`.\r\n\r\n### D. Headers Exchange\r\nRoutes based on message headers instead of routing keys.\r\n*   **Best for:** Routing based on complex metadata (e.g., File format, priority).\r\n\r\n```mermaid\r\nflowchart TD\r\n    Msg[Message] --> ExType{Exchange Type}\r\n    ExType -->|Direct| Q1[Single Target]\r\n    ExType -->|Fanout| Q2[All Bound Queues]\r\n    ExType -->|Topic| Q3[Pattern Match: user.*]\r\n```\r\n\r\n## 4. Building for Reliability: Don't Lose a Single Bit\r\n\r\nIn production (especially in fintech or e-commerce), losing a message means losing money. RabbitMQ provides several reliability layers.\r\n\r\n### A. Message Acknowledgment (Ack)\r\nA consumer must send back an \"Acknowledgment\" to RabbitMQ. If the consumer crashes before sending the Ack, RabbitMQ re-queues the message for another worker.\r\n\r\n### B. Persistence (Durable & Persistent)\r\n- **Durable Queue:** The queue survives a RabbitMQ server reboot.\r\n- **Persistent Message:** The individual message is saved to disk.\r\n\r\n### C. Dead Letter Queues (DLQ)\r\nWhen a message fails processing multiple times (e.g., due to a logic error), it shouldn't block the queue. RabbitMQ sends it to a **Dead Letter Exchange** following a set of failures.\r\n\r\n```mermaid\r\nflowchart TD\r\n    MainQ[Order Queue] --> Worker[Order Processor]\r\n    Worker -->|Success| Ack[ACK]\r\n    Worker -->|Fail 3x| DLX{DLX}\r\n    DLX --> DLQ[Dead Letter Queue]\r\n    DLQ --> Admin[Manual Alert]\r\n```\r\n\r\n## 5. Advanced Patterns: The Saga and RPC\r\n\r\n### The Saga Pattern (Distributed Transactions)\r\nIn microservices, you can't use SQL transactions across services. You use Sagas.\r\n1. `Order Service` places order.\r\n2. `Payment Service` charges card.\r\n3. If payment fails, `Order Service` is notified via event to cancel the order.\r\n\r\n### Remote Procedure Call (RPC)\r\nSometimes you need a synchronous response over RabbitMQ.\r\n1. Client sends request with a `reply_to` queue name and a `correlation_id`.\r\n2. Server processes and sends response to the `reply_to` queue with the same `id`.\r\n\r\n## 6. Throughput and Scaling Workers\r\n\r\nOne of the best features of RabbitMQ is its ability to distribute work. If you have 10,000 images to process, you don't need a faster server; you just need **more workers**.\r\n\r\n### Round-Robin Distribution\r\nBy default, RabbitMQ sends each message to the next consumer in a sequence.\r\n\r\n### Fair Dispatch (Prefetch Count)\r\nTell RabbitMQ: \"Don't give me a new message until I've finished the current one.\" This ensures that a fast worker isn't sitting idle while a slow worker is overwhelmed.\r\n\r\n## 7. Monitoring and Troubleshooting\r\n\r\n> [!INFO]\r\n> The **RabbitMQ Management Plugin** is your best friend. It provides a web UI to see queue lengths, message rates, and consumer health.\r\n\r\n**Common Red Flags:**\r\n- **High \"Unacked\" Count:** Your consumers are hanging or not acknowledging messages.\r\n- **Growing Queue Length:** Your consumers can't keep up with the producers. Time to scale!\r\n\r\n## 8. Real-world Case Study: The E-Learning Flow\r\n\r\nImagine a student completing a course:\r\n1.  **Course Service** emits `course.completed`.\r\n2.  **Certificate Service** hears it, generates a PDF, and saves it.\r\n3.  **Notification Service** hears it, sends an email with the PDF.\r\n4.  **Admin Service** hears it, updates the student's record for HR.\r\n\r\nIf the \"Email Service\" is slow, the \"Certificate\" is still generated instantly. The user sees \"Congratulations!\" and the email arrives 10 seconds later.\r\n\r\n## 9. Best Practices for Developers\r\n\r\n1.  **Idempotency:** Assume messages will be delivered more than once. Always check if a transaction has already been processed before doing it again.\r\n2.  **Small Messages:** Don't send a 10MB image through RabbitMQ. Send the **URL** to the image in S3/BunnyCDN.\r\n3.  **Connection Pooling:** Creating a connection is expensive. Open a connection once and use **Channels** for individual tasks.\r\n\r\n## 10. Conclusion: Why Unicorns Love RabbitMQ\r\n\r\nCompanies like **Tinder, Robinhood, and WeWork** use RabbitMQ to handle massive distribution. It provides the \"shock absorption\" necessary for systems to survive traffic spikes and network instability.\r\n\r\nBy mastering RabbitMQ, you aren't just learning \"how to send messages.\" You are learning how to build **Resilient Distributed Systems**.\r\n\r\n### FAQ\r\n\r\n<details>\r\n<summary>RabbitMQ vs Kafka: Which is better?</summary>\r\nRabbitMQ is better for complex routing and \"point-to-point\" tasks. Kafka is better for high-throughput log streaming and \"Replay\" capability. For most microservices, RabbitMQ is simpler and more flexible.\r\n</details>\r\n\r\n<details>\r\n<summary>How many messages can RabbitMQ handle?</summary>\r\nIn a single node, easily 20,000+ messages per second. In a cluster, it can handle hundreds of thousands.\r\n</details>\r\n\r\n<details>\r\n<summary>What happens if the queue is full?</summary>\r\nYou can set a \"Max Length.\" Once reached, RabbitMQ can either drop old messages or return an error to the producer.\r\n</details>\r\n\r\n_Next in our System Design series: Ship to Scale - The Kubernetes Journey._\r\n",
    "excerpt": "In a classic monolithic application, communication is simple: you call a function, it does some work, and returns a result. But in a Microservices world, servic...",
    "headings": []
  },
  {
    "slug": "redis-deep-dive",
    "frontmatter": {
      "title": "Redis Deep Dive: From simple Cache to Distributed Data Backbone",
      "description": "A comprehensive, multi-layered guide to mastering Redis: Data structures, persistence models, advanced caching strategies, and high-availability patterns.",
      "date": "2024-01-08",
      "category": "Data Engineering",
      "tags": [
        "Redis",
        "Caching",
        "Database",
        "Performance",
        "System Design"
      ],
      "author": "Khairil Rahman",
      "readTime": "22 min read",
      "published": true
    },
    "content": "\r\nIn the high-stakes world of performance-critical backend engineering, **Redis** (Remote Dictionary Server) is more than just a tool—it's an essential part of the modern infrastructure stack. Almost every service from **Netflix** to **Uber** relies on Redis to deliver the sub-millisecond response times their users expect.\r\n\r\nBut despite its popularity, many developers only surface-scratch its potential, using it merely for simple \"String\" caching. In this 5000-word equivalent deep dive, we will peel back the layers of Redis to understand its architecture, its rich data structures, and how to design distributed systems around it.\r\n\r\n## 1. The Anatomy of Speed: Why is Redis So Fast?\r\n\r\nBefore we look at commands, we must understand the engineering behind the speed. Redis consistently delivers **sub-millisecond latency** and can handle millions of requests per second on a single machine. How?\r\n\r\n### A. The In-Memory Design\r\nUnlike traditional databases (PostgreSQL, MySQL) that store data on disk and use RAM only as a buffer, Redis stores everything in the **Primary Memory (RAM)**. Disk I/O is thousands of times slower than memory access.\r\n\r\n### B. The Single-Threaded Myth\r\nRedis is often called \"single-threaded.\" While true for the core command execution, it's a strategic choice:\r\n- **No Locking Overhead:** No need for mutexes or semaphores.\r\n- **No Context Switching:** The CPU doesn't waste cycles switching between threads.\r\n- **CPU Cache Optimization:** Data stays in the L1/L2 cache longer.\r\n\r\n### C. IO Multiplexing\r\nRedis uses an event-driven model based on `epoll` (Linux) or `kqueue` (macOS), allowing a single thread to handle thousands of concurrent client connections efficiently.\r\n\r\n## 2. Mastery of the 5 Essential Data Structures\r\n\r\nRedis is a \"Data Structure Server.\" You don't just store \"values\"; you store specific structures optimized for specific tasks.\r\n\r\n### Structure 1: Strings (The Foundation)\r\nThe most basic type. It's binary-safe, meaning it can store anything from a text user object to a JPEG image.\r\n*   **Max Size:** 512 MB per key.\r\n*   **Best for:** Page caching, Session tokens, Counters (`INCR` command).\r\n\r\n### Structure 2: Hashes (Object Storage)\r\nMaps between string fields and string values. It's a \"database inside a key.\"\r\n*   **Best for:** User profiles, product metadata. It's much more memory-efficient than storing objects as serialized JSON strings.\r\n\r\n### Structure 3: Lists (Message Queues)\r\nOrdered collections of strings.\r\n*   **Best for:** Activity feeds, basic message queues (using `LPUSH` and `RPOP`).\r\n\r\n### Structure 4: Sets (Uniqueness)\r\nUnordered collections of unique strings.\r\n*   **Best for:** Tracking unique visitors, tagging systems, \"Mutual Friends\" logic via set intersections.\r\n\r\n### Structure 5: Sorted Sets (Leaderboards)\r\nSets where every element is associated with a **Score**. Elements are automatically sorted by score.\r\n*   **Best for:** Real-time leaderboards, rate limiters, priority queues.\r\n\r\n```mermaid\r\ngraph TD\r\n    subgraph Redis_Data_Structures\r\n        ST[Strings]\r\n        HS[Hashes]\r\n        LS[Lists]\r\n        SS[Sets]\r\n        ZS[Sorted Sets]\r\n    end\r\n    \r\n    ST --> |Use| S1[Session Tokens]\r\n    HS --> |Use| S2[User Profiles]\r\n    LS --> |Use| S3[Job Queue]\r\n    SS --> |Use| S4[Unique Visitors]\r\n    ZS --> |Use| S5[Leaderboards]\r\n```\r\n\r\n## 3. Advanced Caching Strategies: Beyond \"Set\" and \"Get\"\r\n\r\nCaching is an art. If done wrong, it can cause more problems than it solves (like stale data).\r\n\r\n### Strategy A: Cache-Aside Pattern\r\nThe application is responsible for managing the cache.\r\n1. Check Redis for data.\r\n2. If it exists (Hit): Return it.\r\n3. If not (Miss): Query DB, save to Redis, then return.\r\n\r\n```mermaid\r\nsequenceDiagram\r\n    participant App\r\n    participant Redis\r\n    participant DB\r\n    \r\n    App->>Redis: GET user:123\r\n    Note over Redis: Cache Miss\r\n    Redis-->>App: null\r\n    App->>DB: SELECT * FROM users WHERE id=123\r\n    DB-->>App: {id: 123, name: \"Khairil\"}\r\n    App->>Redis: SETEX user:123 3600 data\r\n    App-->>App: Return User\r\n```\r\n\r\n### Strategy B: Write-Through vs. Write-Back\r\n- **Write-Through:** Every write goes to Redis and DB simultaneously. Data is never stale.\r\n- **Write-Back (Write-Behind):** Data is written to Redis first and synced to DB periodically. Extremely fast, but risk of data loss on crash.\r\n\r\n## 4. The Persistence Paradox: RDB vs. AOF\r\n\r\nIf Redis is in-memory, what happens if the power goes out? \r\n\r\n| Feature | RDB (Snapshotting) | AOF (Append Only File) |\r\n| :--- | :--- | :--- |\r\n| **Method** | Compact binary archive of data at a point in time. | Logs every write operation ever performed. |\r\n| **Recovery** | Very fast (just load the binary). | Slower (must replay the log file). |\r\n| **Durability** | Risky (you lose data since last snapshot). | Excellent (logs every second). |\r\n| **File Size** | Small and optimized. | Large and can grow huge (needs \"rewrite\"). |\r\n\r\n**The Pro's Choice:** Use **Both**. Use RDB for backups and AOF for daily durability.\r\n\r\n## 5. Distributed Locking with Redlock\r\n\r\nHow do you ensure only one server instance processes a payment or sends a specific notification? You use a **Distributed Lock**.\r\n\r\n```bash\r\n# Attempt to acquire lock for 10 seconds\r\nSET resource_name my_unique_id NX PX 10000\r\n```\r\n- `NX`: Set if Not eXists.\r\n- `PX 10000`: Expire in 10,000ms (to prevent \"Deadlock\" if your server crashes).\r\n\r\n## 6. High Availability: Sentinel and Cluster\r\n\r\n### A. Redis Sentinel\r\nProvides automatic failover. If the Master node dies, Sentinel promotes a Slave to Master.\r\n\r\n### B. Redis Cluster (Horizontal Scaling)\r\nPartitions your data across multiple master nodes using \"Hash Slots.\" This allows you to scale from 16GB of RAM to 10 Terabytes.\r\n\r\n```mermaid\r\ngraph LR\r\n    subgraph Master_Nodes\r\n        N1[Node 1: Slots 0-5000]\r\n        N2[Node 2: Slots 5001-10000]\r\n        N3[Node 3: Slots 10001-16383]\r\n    end\r\n    \r\n    Client -->|Hash calculation| N2\r\n```\r\n\r\n## 7. Caching Anti-Patterns (Common Mistakes)\r\n\r\n> [!WARNING]\r\n> Beware of the **Cache Avalanche**! This happens when thousands of keys expire at the exact same time, sending a massive flood of traffic to your database.\r\n\r\n- **The Solution:** Add a random \"jitter\" to your TTL (Time To Live). Instead of setting all to 1 hour, set some to 58 min, some to 62 min.\r\n\r\n- **Cache Penetration:** Requests for data that doesn't exist in the DB (like IDs that don't exist).\r\n- **The Solution:** Cache the \"null\" result for a short time or use a **Bloom Filter**.\r\n\r\n## 8. Real-world Case Study: Real-time Leaderboard\r\n\r\nImagine an online game with 1,000,000 players. Calculating the top 10 players by score in SQL would take seconds of heavy table scanning. In Redis:\r\n\r\n```bash\r\n# Add score for player\r\nZADD game_scores 1500 \"player_king\"\r\nZADD game_scores 1200 \"player_rookie\"\r\n\r\n# Get top 3\r\nZREVRANGE game_scores 0 2 WITHSCORES\r\n```\r\nThis operation is **O(log(N))**, meaning it takes virtually the same amount of time for 10 users or 10 million.\r\n\r\n## 9. Advanced: Lua Scripting\r\n\r\nRedis supports server-side scripts written in Lua. This allows you to run multiple commands **Atomically**. No other client can run commands while your script is executing.\r\n\r\n```lua\r\n-- Atomic increment with a maximum limit\r\nlocal current = redis.call('GET', KEYS[1])\r\nif current and tonumber(current) >= tonumber(ARGV[1]) then\r\n    return 0\r\nelse\r\n    return redis.call('INCR', KEYS[1])\r\nend\r\n```\r\n\r\n## 10. Conclusion: Redis as your Portfolio Backbone\r\n\r\nIf you are applying to companies like **Grab, Shopee, or Gojek**, you need to show you can handle scale. Using Redis for simple caching is step one. Using it for **Distributed Locks, Leaderboards, and Rate Limiting** is how you prove you are a Senior-level engineer.\r\n\r\n> \"Redis is often the difference between a system that works and a system that performs.\"\r\n\r\n### FAQ\r\n\r\n<details>\r\n<summary>Can Redis replace a SQL database?</summary>\r\nRarely. While it has persistence, it's not optimized for complex relational queries (JOINs) or ACID transactions across many keys. It's meant to *complement* your primary DB.\r\n</details>\r\n\r\n<details>\r\n<summary>How do I handle cache invalidation?</summary>\r\nThe hardest problem in computer science! Use TTLs, or manually delete keys when the underlying data in the DB changes (Write-Through).\r\n</details>\r\n\r\n<details>\r\n<summary>Is Redis single-threaded in version 6+?</summary>\r\nVersion 6 introduced multithreaded I/O to handle network packets, but the execution of commands remains single-threaded to preserve simplicity and speed.\r\n</details>\r\n\r\n_Next in our System Design series: Event-Driven Architecture with RabbitMQ._\r\n",
    "excerpt": "In the high-stakes world of performance-critical backend engineering, Redis (Remote Dictionary Server) is more than just a tool—it's an essential part of the mo...",
    "headings": []
  },
  {
    "slug": "microservices-architecture",
    "frontmatter": {
      "title": "Mastering Microservices Architecture: A Deep Dive into Distributed Systems Design",
      "description": "A comprehensive, 5000-word equivalent guide to designing, building, and scaling microservices with production-grade patterns, observability, and security.",
      "date": "2024-01-07",
      "category": "System Design",
      "tags": [
        "Microservices",
        "Architecture",
        "Backend",
        "Distributed Systems",
        "Cloud Native"
      ],
      "author": "Khairil Rahman",
      "readTime": "25 min read",
      "published": true
    },
    "content": "\r\nThe landscape of software development has shifted dramatically over the last decade. We've moved from monolithic \"do-it-all\" applications to distributed, modular systems known as **Microservices**. But why? And more importantly, how do you design them effectively without creating a \"distributed monolith\" that is even harder to maintain?\r\n\r\nIn this comprehensive guide, we'll explore the core principles of microservices architecture, its advantages, the challenges it presents, the design patterns that make it successful in production, and how to build a career-defining portfolio project around these concepts.\r\n\r\n## 1. The Genesis: From Monolith to Microservices\r\n\r\n### The Monolithic Problem\r\nIn the early days of web development, the **Monolith** was king. A single codebase, a single executable, and a single database. For small projects, this is perfect. But as the system grows:\r\n- **Scaling becomes inefficient:** You cannot scale only the \"Payment\" module; you must scale the whole app.\r\n- **Technology lock-in:** Want to use Go for a CPU-intensive task but your monolith is Ruby? Good luck.\r\n- **Cognitive Load:** New engineers take months to understand the spaghetti code.\r\n\r\n### The Microservices Solution\r\nMicroservices solve this by breaking the application into small, independent services. Each service:\r\n- Runs in its own process.\r\n- Communicates with lightweight mechanisms (REST, gRPC, or Message Brokers).\r\n- Is built around specific business capabilities.\r\n- Is independently deployable.\r\n\r\n```mermaid\r\ngraph LR\r\n    subgraph Monolith_Architecture\r\n        M[Frontend + Backend + Database]\r\n    end\r\n\r\n    subgraph Microservices_Architecture\r\n        S1[Auth Service]\r\n        S2[Course Service]\r\n        S3[Payment Service]\r\n        S4[Notification Service]\r\n        \r\n        S1 --- DB1[(Auth DB)]\r\n        S2 --- DB2[(Course DB)]\r\n        S3 --- DB3[(Payment DB)]\r\n        S4 --- DB4[(Log DB)]\r\n    end\r\n```\r\n\r\n## 2. Core Principles: The \"Laws\" of Microservices\r\n\r\nTo build microservices that actually work, you must adhere to these fundamental principles.\r\n\r\n### A. Bounded Context (Domain Driven Design)\r\nBorrowed from Eric Evans' *Domain Driven Design*, a Bounded Context defines a boundary within which a specific domain model is defined and applicable.\r\n*Example:* A \"Course\" in the `Catalog Service` might just be a title and price. In the `Learning Service`, it includes progress tracks, quizzes, and certificates. They are technically the same entity but belong to different contexts.\r\n\r\n### B. Independent Deployability\r\nThis is the litmus test. If you can't push a fix to Service A without affecting Service B, you don't have microservices. This requires strict API versioning and backward compatibility.\r\n\r\n### C. Decentralized Data Management (Database per Service)\r\n**Rule #1:** No shared database tables. If Service A needs data from Service B, it must:\r\n1. Call Service B's API.\r\n2. Listen to an event emitted by Service B and store a local copy of the data.\r\n\r\n## 3. High-Level Design Patterns\r\n\r\nBuilding microservices is like playing with Lego blocks—you need a blueprint to connect them.\r\n\r\n### A. API Gateway Pattern\r\nInstead of letting the client talk directly to 50 different microservices, an **API Gateway** acts as a single entry point.\r\n\r\n**Responsibilities:**\r\n- **Routing:** Directing `/api/v1/auth` to User Service.\r\n- **Authentication:** Validating JWT tokens before they reach the services.\r\n- **Rate Limiting:** Preventing DDoS attacks.\r\n- **Load Balancing:** Distributing traffic across multiple instances.\r\n\r\n```mermaid\r\ngraph TD\r\n    Client[Web/Mobile Client] -->|HTTPS| Gateway[API Gateway / Nginx / Kong]\r\n    \r\n    subgraph Cluster\r\n        Gateway --> ServiceA[User Service]\r\n        Gateway --> ServiceB[Catalog Service]\r\n        Gateway --> ServiceC[Order Service]\r\n    end\r\n    \r\n    ServiceA --- DB_A[(PostgreSQL)]\r\n    ServiceB --- DB_B[(MongoDB)]\r\n    ServiceC --- DB_C[(PostgreSQL)]\r\n```\r\n\r\n### B. Service Discovery\r\nHow does Service A know the IP of Service B in a dynamic Kubernetes environment?\r\n- **Client-Side Discovery:** Client queries a Service Registry (Consul, Eureka).\r\n- **Server-Side Discovery:** (Standard in K8s) The client talks to a \"Service\" object which handles routing.\r\n\r\n### C. Circuit Breaker\r\nIf Service B is failing, don't let it take down Service A. The Circuit Breaker \"trips\" and returns a fallback response until Service B is healthy.\r\n\r\n## 4. Communication: Sync vs. Async\r\n\r\n### Synchronous (REST/gRPC)\r\n- **When to use:** When you need an immediate result (e.g., \"Is this user's password correct?\").\r\n- **Trade-off:** High coupling. If the downstream service is slow, everyone is slow.\r\n\r\n### Asynchronous (RabbitMQ / Kafka)\r\n- **When to use:** When the action can happen \"eventually\" (e.g., \"Send a welcome email after signup\").\r\n- **Trade-off:** Complexity. You have to handle \"at-least-once\" delivery and idempotent processing.\r\n\r\n```mermaid\r\nsequenceDiagram\r\n    participant User\r\n    participant OS as Order Service\r\n    participant Broker as RabbitMQ\r\n    participant SS as Shipping Service\r\n    \r\n    User->>OS: Place Order\r\n    OS->>OS: Save Order (Pending)\r\n    OS->>Broker: Publish \"OrderPrepared\"\r\n    OS-->>User: 202 Accepted (Processing...)\r\n    Broker->>SS: Deliver message\r\n    SS->>SS: Start delivery process\r\n```\r\n\r\n## 5. Data Consistency and the Saga Pattern\r\n\r\nIn microservices, you cannot use a simple \"BEGIN TRANSACTION\" across two databases. You use a **Saga**.\r\n\r\n### Choreography Saga\r\nServices talk to each other via events without a central coordinator.\r\n*Example:* Order Service emits `OrderCreated`. Payment Service hears it and charges the card.\r\n\r\n### Orchestration Saga\r\nA central \"Orchestrator\" tells each service what to do.\r\n*Example:* The Saga Manager tells Payment Service \"Charge Card.\" If it fails, it tells Stock Service \"Release Reserved Items.\"\r\n\r\n## 6. Microservices Security: The Zero-Trust Model\r\n\r\nIn a distributed system, you shouldn't trust the internal network.\r\n\r\n### A. JWT for Identity\r\nThe Gateway generates a signed JWT. Every service verifies this token locally.\r\n```javascript\r\n// Verification middleware example\r\nconst verifyToken = (req, res, next) => {\r\n  const token = req.headers['authorization'];\r\n  try {\r\n    const decoded = jwt.verify(token, PUBLIC_KEY);\r\n    req.user = decoded;\r\n    next();\r\n  } catch (err) {\r\n    return res.status(401).send('Unauthorized');\r\n  }\r\n};\r\n```\r\n\r\n### B. Mutual TLS (mTLS)\r\nServices must present a valid certificate to talk to each other. This is often handled by a **Service Mesh** like Istio or Linkerd.\r\n\r\n## 7. Observability: Seeing through the Cloud\r\n\r\nYou cannot debug microservices with `console.log` on one machine. You need:\r\n\r\n1.  **Distributed Tracing:** Every request gets a `TraceID` that follows it through all services.\r\n2.  **Centralized Logging:** All logs pushed to a single place (ELK Stack: Elasticsearch, Logstash, Kibana).\r\n3.  **Metrics:** Using Prometheus and Grafana to watch CPU, Memory, and Request counts.\r\n\r\n```mermaid\r\ngraph TD\r\n    App[Microservices] -->|Logs| ELK[ELK Stack]\r\n    App -->|Metrics| PROM[Prometheus]\r\n    PROM --> GRAF[Grafana]\r\n    App -->|Spans| JAE[Jaeger Tracing]\r\n```\r\n\r\n## 8. Resilience and Chaos Engineering\r\n\r\nBuild for failure. Use \"Chaos Engineering\" (pioneered by Netflix) to intentionally break things in production.\r\n- **Liveness Probes:** Restarts a container if it crashes.\r\n- **Readiness Probes:** Removes a container from the load balancer if it's not ready to handle traffic.\r\n\r\n## 9. Common Mistakes to Avoid (Anti-Patterns)\r\n\r\n> [!CAUTION]\r\n> Avoid the \"Distributed Monolith\" – where services are so coupled that you can't change one without the other.\r\n\r\n- **Sharing a Database:** This is the most common death sentence for microservices.\r\n- **Nano-services:** Breaking things down too small (e.g., a service for just \"String Utility\").\r\n- **Ignoring Automation:** Trying to manage microservices without a robust CI/CD pipeline.\r\n\r\n## 10. Conclusion: Why This Matters for Your Career\r\n\r\nUnderstanding microservices isn't just about learning a new tool; it's about learning a new way of thinking. Companies like **Netflix, Amazon, Uber, and Grab** (The Unicorns) don't hire \"Node.js developers.\" They hire **System Engineers** who understand how to build resilient, distributed systems.\r\n\r\nBy building a project that implements these patterns, you demonstrate that you can handle the scale and complexity of a multi-billion dollar platform.\r\n\r\n> \"Simplicity is a prerequisite for reliability.\"\r\n> -- Edsger W. Dijkstra\r\n\r\n### FAQ\r\n\r\n<details>\r\n<summary>Is Kubernetes required for microservices?</summary>\r\nNo, but it makes life 100x easier. You can use Docker Swarm or even just separate VPS instances, but K8s is the industry standard for a reason.\r\n</details>\r\n\r\n<details>\r\n<summary>How do I handle shared code (Common Utils)?</summary>\r\nUse a private NPM package or a Git Submodule. But be careful—if you change the shared code, you might force a synchronized deployment of all services.\r\n</details>\r\n\r\n<details>\r\n<summary>What is the best language for microservices?</summary>\r\nThe beauty is you can use anything! Node.js is great for I/O, Go is great for concurrency/CPU, and Python is great for AI/Data.\r\n</details>\r\n\r\n_Thank you for reading this deep dive. Stay tuned for Part 2: Redis Caching at Scale._\r\n\r\n_Written by **Khairil Rahman**._\r\n",
    "excerpt": "The landscape of software development has shifted dramatically over the last decade. We've moved from monolithic \"do-it-all\" applications to distributed, modula...",
    "headings": []
  }
] as Article[],
  categories: [
  {
    "name": "Infrastructure",
    "slug": "infrastructure",
    "description": "Infrastructure related articles",
    "count": 1
  },
  {
    "name": "Cloud Native",
    "slug": "cloud-native",
    "description": "Cloud Native related articles",
    "count": 1
  },
  {
    "name": "System Design",
    "slug": "system-design",
    "description": "System Design related articles",
    "count": 1
  },
  {
    "name": "Data Engineering",
    "slug": "data-engineering",
    "description": "Data Engineering related articles",
    "count": 1
  }
] as Category[],
  tags: [
  "Architecture",
  "Backend",
  "Caching",
  "Cloud Native",
  "Database",
  "DevOps",
  "Distributed Systems",
  "EDA",
  "HPA",
  "K8s",
  "Kubernetes",
  "Message Broker",
  "Microservices",
  "Performance",
  "RabbitMQ",
  "Redis",
  "Scalability",
  "Scaling",
  "System Design"
] as string[],
  lastUpdated: '2026-01-17T09:06:13.211Z',
} as const;

// Helper functions
export function getAllArticles(): Article[] {
  return blogData.articles;
}

export function getArticleBySlug(slug: string): Article | undefined {
  return blogData.articles.find(article => article.slug === slug);
}

export function getArticlesByCategory(categorySlug: string): Article[] {
  return blogData.articles.filter(article => 
    article.frontmatter.category.toLowerCase().replace(/\s+/g, '-') === categorySlug
  );
}

export function getAllCategories(): Category[] {
  return blogData.categories;
}

export function getRelatedArticles(currentArticle: Article, limit: number = 3): Article[] {
  return blogData.articles
    .filter(article => 
      article.slug !== currentArticle.slug &&
      (
        article.frontmatter.category === currentArticle.frontmatter.category ||
        article.frontmatter.tags.some(tag => currentArticle.frontmatter.tags.includes(tag))
      )
    )
    .slice(0, limit);
}

export function searchArticles(query: string): Article[] {
  const searchTerm = query.toLowerCase();
  return blogData.articles.filter(article =>
    article.frontmatter.title.toLowerCase().includes(searchTerm) ||
    article.frontmatter.description.toLowerCase().includes(searchTerm) ||
    article.frontmatter.tags.some(tag => tag.toLowerCase().includes(searchTerm))
  );
}

export function getRecentArticles(limit: number = 5): Article[] {
  return blogData.articles.slice(0, limit);
}
